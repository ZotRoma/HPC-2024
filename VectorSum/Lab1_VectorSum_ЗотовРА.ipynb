{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "!nvcc --version\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1w0NXmoQDFh",
        "outputId": "da767d29-a54d-4d7e-8819-f7829b7e8e2a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpcqgygbk7\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>\n",
        "#include <numeric> // для std::accumulate\n",
        "\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "// Ядро CUDA для вычисления суммы с использованием сокращения (reduction)\n",
        "__global__ void sum_reduction(const int *input, int *output, int size) {\n",
        "    __shared__ int shared_data[BLOCK_SIZE];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Инициализируем shared memory (заполняем в общей памяти блока элементы)\n",
        "    shared_data[tid] = (i < size) ? input[i] : 0;\n",
        "    __syncthreads();\n",
        "\n",
        "    // Сумма сокращения\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        // суть в том, что сначала мы рассчитываем значение для половины массива, потом для оставшейся половины и т.д. пока не дойдем то 1 элемента\n",
        "        if (tid < stride) {\n",
        "            shared_data[tid] += shared_data[tid + stride];\n",
        "        }\n",
        "        // синхронизация, чтобы все потоки досчитали значения\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Сохраняем результат блока (элемент, который хранит сумму всего блока)\n",
        "    if (tid == 0) {\n",
        "        output[blockIdx.x] = shared_data[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Ядро CUDA для распределенного суммирования\n",
        "__global__ void distributed_sum_reduction(const int *input, int *output, int size, int elements_per_thread) {\n",
        "    __shared__ int shared_data[BLOCK_SIZE];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int block_start_index = blockIdx.x * blockDim.x * elements_per_thread;\n",
        "    int local_sum = 0;\n",
        "\n",
        "    // Каждая нить суммирует свои элементы\n",
        "    for (int i = 0; i < elements_per_thread; ++i) {\n",
        "        int index = block_start_index + tid * elements_per_thread + i;\n",
        "        if (index < size) {\n",
        "            local_sum += input[index];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Сохраняем локальную сумму нити в shared memory\n",
        "    shared_data[tid] = local_sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    // Суммирование в одной нити (например, нить 0) для блока\n",
        "    if (tid == 0) {\n",
        "        int block_sum = 0;\n",
        "        for (int i = 0; i < blockDim.x; ++i) {\n",
        "            block_sum += shared_data[i];\n",
        "        }\n",
        "        output[blockIdx.x] = block_sum;  // Сохраняем итоговую сумму блока\n",
        "    }\n",
        "}\n",
        "\n",
        "// Функция для запуска ядра CUDA (reduction)\n",
        "int sum_vector_gpu(const std::vector<int>& vec) {\n",
        "    int size = vec.size();\n",
        "    int *d_input, *d_output;\n",
        "\n",
        "    // Вычисляем количество блоков\n",
        "    int grid_size = (size + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "    // Выделяем память на устройстве\n",
        "    cudaMalloc(&d_input, size * sizeof(int));\n",
        "    cudaMalloc(&d_output, grid_size * sizeof(int));\n",
        "\n",
        "    // Копируем данные на устройство\n",
        "    cudaMemcpy(d_input, vec.data(), size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Запускаем ядро\n",
        "    sum_reduction<<<grid_size, BLOCK_SIZE>>>(d_input, d_output, size);\n",
        "\n",
        "    // Копируем промежуточные результаты с устройства на хост\n",
        "    std::vector<int> partial_sums(grid_size);\n",
        "    cudaMemcpy(partial_sums.data(), d_output, grid_size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Завершаем суммирование на CPU\n",
        "    int total_sum = 0;\n",
        "    for (int i = 0; i < grid_size; i++) {\n",
        "        total_sum += partial_sums[i];\n",
        "    }\n",
        "\n",
        "    // Освобождаем память\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return total_sum;\n",
        "}\n",
        "\n",
        "// Функция для запуска распределенного ядра CUDA\n",
        "int sum_vector_gpu_v2(const std::vector<int>& vec, int per) {\n",
        "    int size = vec.size();\n",
        "    int elements_per_thread = per;  // Количество элементов на каждую нить\n",
        "    int *d_input, *d_output;\n",
        "\n",
        "    // Вычисляем количество блоков\n",
        "    int grid_size = (size + elements_per_thread * BLOCK_SIZE - 1) / (elements_per_thread * BLOCK_SIZE);\n",
        "\n",
        "    // Выделяем память на устройстве\n",
        "    cudaMalloc(&d_input, size * sizeof(int));\n",
        "    cudaMalloc(&d_output, grid_size * sizeof(int));\n",
        "\n",
        "    // Копируем данные на устройство\n",
        "    cudaMemcpy(d_input, vec.data(), size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Запускаем ядро CUDA\n",
        "    distributed_sum_reduction<<<grid_size, BLOCK_SIZE>>>(d_input, d_output, size, elements_per_thread);\n",
        "\n",
        "    // Копируем промежуточные результаты с устройства на хост\n",
        "    std::vector<int> partial_sums(grid_size);\n",
        "    cudaMemcpy(partial_sums.data(), d_output, grid_size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Завершаем суммирование на CPU\n",
        "    int total_sum = 0;\n",
        "    for (int i = 0; i < grid_size; i++) {\n",
        "        total_sum += partial_sums[i];\n",
        "    }\n",
        "\n",
        "    // Освобождаем память\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return total_sum;\n",
        "}\n",
        "\n",
        "// Функция для вычисления суммы на CPU\n",
        "int sum_vector_cpu(const std::vector<int>& vec) {\n",
        "    return std::accumulate(vec.begin(), vec.end(), 0);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Размер вектора\n",
        "    for(int i = 1000; i<1000000001; i*=10){\n",
        "      const int vector_size = i; // Можно изменить на другие значения\n",
        "\n",
        "      // Заполняем вектор значениями (например, единицами)\n",
        "      std::vector<int> vec(vector_size, 1);\n",
        "\n",
        "      // Вычисление на GPU\n",
        "      auto start_gpu = std::chrono::high_resolution_clock::now();\n",
        "      int sum_gpu = sum_vector_gpu(vec);\n",
        "      auto end_gpu = std::chrono::high_resolution_clock::now();\n",
        "      std::chrono::duration<double> elapsed_gpu = end_gpu - start_gpu;\n",
        "\n",
        "      // Вычисление на GPU\n",
        "      auto start_gpu_v2 = std::chrono::high_resolution_clock::now();\n",
        "      int sum_gpu_v2 = sum_vector_gpu_v2(vec, 10000);\n",
        "      auto end_gpu_v2 = std::chrono::high_resolution_clock::now();\n",
        "      std::chrono::duration<double> elapsed_gpu_v2 = end_gpu_v2 - start_gpu_v2;\n",
        "\n",
        "      // Вычисление на CPU\n",
        "      auto start_cpu = std::chrono::high_resolution_clock::now();\n",
        "      int sum_cpu = sum_vector_cpu(vec);\n",
        "      auto end_cpu = std::chrono::high_resolution_clock::now();\n",
        "      std::chrono::duration<double> elapsed_cpu = end_cpu - start_cpu;\n",
        "\n",
        "      // Вывод результатов\n",
        "      std::cout << \"Сумма элементов вектора (GPU): \" << sum_gpu << std::endl;\n",
        "      std::cout << \"Время вычисления на GPU с использованием редукции: \" << elapsed_gpu.count() << \" секунд\" << std::endl;\n",
        "\n",
        "      std::cout << \"Сумма элементов вектора (GPU): \" << sum_gpu_v2 << std::endl;\n",
        "      std::cout << \"Время вычисления на GPU с использованием распределнных вычислений: \" << elapsed_gpu_v2.count() << \" секунд\" << std::endl;\n",
        "\n",
        "      std::cout << \"Сумма элементов вектора (CPU): \" << sum_cpu << std::endl;\n",
        "      std::cout << \"Время вычисления на CPU: \" << elapsed_cpu.count() << \" секунд\" << std::endl;\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAH6RgfIylGI",
        "outputId": "edd9d480-7c81-4f61-bb1d-5c8080735f7c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сумма элементов вектора (GPU): 1000\n",
            "Время вычисления на GPU с использованием редукции: 0.0992766 секунд\n",
            "Сумма элементов вектора (GPU): 1000\n",
            "Время вычисления на GPU с использованием распределнных вычислений: 0.000584587 секунд\n",
            "Сумма элементов вектора (CPU): 1000\n",
            "Время вычисления на CPU: 1.0496e-05 секунд\n",
            "Сумма элементов вектора (GPU): 10000\n",
            "Время вычисления на GPU с использованием редукции: 0.000211948 секунд\n",
            "Сумма элементов вектора (GPU): 10000\n",
            "Время вычисления на GPU с использованием распределнных вычислений: 0.000880321 секунд\n",
            "Сумма элементов вектора (CPU): 10000\n",
            "Время вычисления на CPU: 0.000102448 секунд\n",
            "Сумма элементов вектора (GPU): 100000\n",
            "Время вычисления на GPU с использованием редукции: 0.000335278 секунд\n",
            "Сумма элементов вектора (GPU): 100000\n",
            "Время вычисления на GPU с использованием распределнных вычислений: 0.00109437 секунд\n",
            "Сумма элементов вектора (CPU): 100000\n",
            "Время вычисления на CPU: 0.00101687 секунд\n",
            "Сумма элементов вектора (GPU): 1000000\n",
            "Время вычисления на GPU с использованием редукции: 0.00156587 секунд\n",
            "Сумма элементов вектора (GPU): 1000000\n",
            "Время вычисления на GPU с использованием распределнных вычислений: 0.00299595 секунд\n",
            "Сумма элементов вектора (CPU): 1000000\n",
            "Время вычисления на CPU: 0.0101654 секунд\n",
            "Сумма элементов вектора (GPU): 10000000\n",
            "Время вычисления на GPU с использованием редукции: 0.0119 секунд\n",
            "Сумма элементов вектора (GPU): 10000000\n",
            "Время вычисления на GPU с использованием распределнных вычислений: 0.0144215 секунд\n",
            "Сумма элементов вектора (CPU): 10000000\n",
            "Время вычисления на CPU: 0.102186 секунд\n",
            "Сумма элементов вектора (GPU): 100000000\n",
            "Время вычисления на GPU с использованием редукции: 0.100887 секунд\n",
            "Сумма элементов вектора (GPU): 100000000\n",
            "Время вычисления на GPU с использованием распределнных вычислений: 0.104473 секунд\n",
            "Сумма элементов вектора (CPU): 100000000\n",
            "Время вычисления на CPU: 1.03968 секунд\n",
            "Сумма элементов вектора (GPU): 1000000000\n",
            "Время вычисления на GPU с использованием редукции: 0.956433 секунд\n",
            "Сумма элементов вектора (GPU): 1000000000\n",
            "Время вычисления на GPU с использованием распределнных вычислений: 1.05276 секунд\n",
            "Сумма элементов вектора (CPU): 1000000000\n",
            "Время вычисления на CPU: 11.2147 секунд\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}